{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreating digest2 output for all the XML files \n",
    "We want to recreate the digest2 output for all the XML files from the NEO Surveyor mission. The digest2 score needs to contain all the available values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up files and directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "import xmltodict\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the XML files\n",
    "xml_dir = \"NEOSurveyordata-20241021/\"\n",
    "xml_files = [\n",
    "    \"2024-10-21T16_54_54.398_000000R8.xml\"\n",
    "]\n",
    "\n",
    "# Off-ecliptic and on-ecliptic XML files\n",
    "off_ecliptic_file = xml_dir+\"off_ecl_tracklet2desig3.dat\"\n",
    "on_ecliptic_file = xml_dir+\"on_ecl_tracklet2desig3.dat\"\n",
    "\n",
    "# Digest2 executable\n",
    "digest2_exec = \"digest2/digest2/digest2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUTINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2522  observations in  NEOSurveyordata-20241021/2024-10-21T16_54_54.398_000000R8.xml\n",
      "558  unique trksubs in  NEOSurveyordata-20241021/2024-10-21T16_54_54.398_000000R8.xml\n"
     ]
    }
   ],
   "source": [
    "#Analyze each XML file\n",
    "def analyze_xml(xml_file):\n",
    "    \"\"\" Analyze the content of the XML file. \"\"\"\n",
    "    with open(xml_file, 'r') as file:\n",
    "        xml_string = file.read()\n",
    "\n",
    "    # Convert the XML string to a Python dictionary\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "        \n",
    "    # Convert the dictionary to a DataFrame\n",
    "    xml_df = pd.DataFrame(xml_dict['ades']['obsBlock']['obsData']['optical'])\n",
    "    \n",
    "    # Count the number of observations\n",
    "    print(f'{xml_df.shape[0]}  observations in  {xml_file}')\n",
    "    # Count the number of unique trksubs\n",
    "    print(f'{xml_df[\"trkSub\"].nunique()}  unique trksubs in  {xml_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run digest2 code on single file\n",
    "def run_digest2(file_path):\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        return False\n",
    "    print(f\"Processing: {file_path}\")\n",
    "\n",
    "    start_time = time.time() # starting a timer\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "        f\"{digest2_exec} -c MPC.config {file_path}\",\n",
    "        capture_output=True, text=True, check=True, shell=True\n",
    "        )\n",
    "        if result.stderr:\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        print(f\"Command output: {e.output}\")\n",
    "        return False\n",
    "\n",
    "    end_time = time.time() # ending the timer\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Time taken for {file_path}: {elapsed_time:.4f} seconds\\n\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match trksubs with designations from NEO Surveyor \n",
    "def match_desig_trksub(offecliptic_file:str, onecliptic_file:str) -> dict:\n",
    "    \"\"\" Create a dictionary that matches the trksubs to the designations given by the NEO Surveyor Team \"\"\"\n",
    "\n",
    "    file_list = [offecliptic_file, onecliptic_file]\n",
    "    # Empty dictionary\n",
    "    trksub_desig = {}\n",
    "    \n",
    "    # Count the number of NEAs and not NEAs in the file\n",
    "    nnea = 0\n",
    "    nnonnea = 0\n",
    "    for f in file_list:\n",
    "        # Check if the file exists\n",
    "        if not os.path.isfile(f):\n",
    "            print(f\"File {f} not found.\")\n",
    "            return None\n",
    "        # Open the file \n",
    "        with open(f, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # Create a dictionary to store the matches\n",
    "                sp = line.split()\n",
    "                trksub = sp[0]\n",
    "                desig = sp[1]\n",
    "                # NEA case\n",
    "                if desig[3] == \"0\":\n",
    "                    NEA = '0'\n",
    "                    nnea += 1\n",
    "                else:\n",
    "                    # MBA case\n",
    "                    NEA = '1'\n",
    "                    nnonnea += 1\n",
    "                trksub_desig[trksub] = [desig, NEA]\n",
    "                \n",
    "    # Print the number of NEAs and not NEAs\n",
    "    print(f\"Total number of NEAs in the off-ecliptic and on-ecliptic data: {nnea}\")\n",
    "    print(f\"Total number of non-NEAs in the off-ecliptic and on-ecliptic data: {nnonnea}\")\n",
    "\n",
    "    return trksub_desig\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output needed by the machine learning code \n",
    "def create_output_format(xml_file: str, digest2_result:list, trksub_desig : dict) -> None:\n",
    "    \"\"\" \n",
    "    Create the output format needed by the machine learning code.\n",
    "    \"\"\"\n",
    "    # Create output file \n",
    "    filtering_output = open(xml_file.replace(\".xml\",\".digest2_filter\"), \"w\", encoding='utf-8')\n",
    "    ml_output = open(xml_file.replace(\".xml\",\".digest2_ml\"), \"w\", encoding='utf-8')\n",
    "    output = open(xml_file.replace(\".xml\",\".digest2\"), \"w\", encoding='utf-8')\n",
    "    # Write header\n",
    "    output.write(\"trksub,Int1,Int2,Neo1,Neo2,MC1,MC2,Hun1,Hun2,Pho1,Pho2,MB1_1,MB1_2,Pal1,Pal2,Han1,Han2,MB2_1,MB2_2,MB3_1,MB3_2,Hil1,Hil2,JTr1,JTr2,JFC1,JFC2\\n\")\n",
    "    # If filtering is true, add the NEA class to the header and call it \"class\"\n",
    "    filtering_output.write(\"trksub,Int1,Int2,Neo1,Neo2,MC1,MC2,Hun1,Hun2,Pho1,Pho2,MB1_1,MB1_2,Pal1,Pal2,Han1,Han2,MB2_1,MB2_2,MB3_1,MB3_2,Hil1,Hil2,JTr1,JTr2,JFC1,JFC2,class\\n\")\n",
    "    # If machine learning is true, add the NEA class to the header and call it \"orbtype\"\n",
    "    ml_output.write(\"trksub,Int1,Int2,Neo1,Neo2,MC1,MC2,Hun1,Hun2,Pho1,Pho2,MB1_1,MB1_2,Pal1,Pal2,Han1,Han2,MB2_1,MB2_2,MB3_1,MB3_2,Hil1,Hil2,JTr1,JTr2,JFC1,JFC2,orbtype\\n\")\n",
    "        \n",
    "    # Count the number of trksubs processed\n",
    "    ntrksub = 0\n",
    "    # Count the number of matched trksubs\n",
    "    nmatched = 0\n",
    "    nnea = 0\n",
    "    nmba = 0\n",
    "    \n",
    "    # Read digest2 results\n",
    "    for line in digest2_result.splitlines()[2:]:\n",
    "        # Split line into columns\n",
    "        sp = line.split()\n",
    "\n",
    "        # Increment the number of trksubs processed\n",
    "        ntrksub += 1\n",
    "        \n",
    "        # Always write the output file for digest2\n",
    "        output.write(','.join(sp) + \"\\n\")\n",
    "        \n",
    "        # Find if the object is an NEA or not\n",
    "        if sp[0] not in trksub_desig:\n",
    "            # If the object is not in the dictionary\n",
    "            continue\n",
    "        \n",
    "        # Increment the number of matched trksubs\n",
    "        nmatched += 1\n",
    "        NEAclass = trksub_desig[sp[0]][1]\n",
    "        if NEAclass == '0':\n",
    "            nnea += 1\n",
    "        else:\n",
    "            nmba += 1\n",
    "        output_string = ','.join(sp) + ',' + NEAclass + \"\\n\"\n",
    "        # Write to filtering output file\n",
    "        filtering_output.write(output_string)\n",
    "        # Write to machine learning output file\n",
    "        ml_output.write(output_string)\n",
    "        \n",
    "    # Close output file\n",
    "    output.close()\n",
    "    filtering_output.close()\n",
    "    ml_output.close()\n",
    "    \n",
    "    print(f\"Processed {ntrksub} trksubs, matched {nmatched} trksubs in {xml_file}.\")\n",
    "    print(f\"Found {nnea} NEAs and {nmba} MBAs in {xml_file}.\")\n",
    "\n",
    "    print(f\"Output file {xml_file.replace('.xml','.digest2')} created.\")\n",
    "    print(f\"Output file {xml_file.replace('.xml','.digest2_filter')} created.\")\n",
    "    print(f\"Output file {xml_file.replace('.xml','.digest2_ml')} created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digest2_output(xml_dir: str, xml_files: list, trksub_desig: dict) -> None:\n",
    "    \n",
    "    # Run digest2 on single files\n",
    "    for xml_file in xml_files:\n",
    "        \n",
    "        # Analyze the XML file\n",
    "        print(\" ------ Analyze XML file ------ \")\n",
    "        analyze_xml(os.path.join(xml_dir, xml_file))\n",
    "\n",
    "        # Run digest2 on the XML file\n",
    "        print(\" ------ Run digest2 on XML file ------ \")\n",
    "        digest2_result = run_digest2(os.path.join(xml_dir, xml_file))\n",
    "        if not digest2_result:\n",
    "            print(f\"Digest2 failed for {xml_file}. Skipping further processing.\")\n",
    "            continue\n",
    "        \n",
    "        if not trksub_desig:\n",
    "            print(\"Failed to match trksubs with designations. Skipping further processing.\")\n",
    "            continue\n",
    "        \n",
    "        # Process the results\n",
    "        print(\" ------ Create output format ------ \")\n",
    "        create_output_format(xml_file, digest2_result.stdout, trksub_desig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze output from digest2\n",
    "def analyze_digest2_output(digest2_file: str, digest2_thresh : int = 65) -> None:\n",
    "    \"\"\" Analyze the output from digest2. \"\"\"\n",
    "\n",
    "    output_df = pd.read_csv(digest2_file)\n",
    "    \n",
    "    # Count the number of NEAs and non-NEAs\n",
    "    nea_count = output_df[output_df['Neo2'] >= digest2_thresh].shape[0]\n",
    "    nonnea_count = output_df[output_df['Neo2'] < digest2_thresh].shape[0]\n",
    "\n",
    "    print(f\"Number of NEAs in {digest2_file}: {nea_count}\")\n",
    "    print(f\"Number of non-NEAs in {digest2_file}: {nonnea_count}\")\n",
    "    \n",
    "# Analyze missing NEAs from digest2\n",
    "def analyze_missing_NEAs(digest2_file: str, digest2_thresh : int = 65) -> None:\n",
    "    \"\"\" Analyze the output from digest2. \"\"\"\n",
    "\n",
    "    output_df = pd.read_csv(digest2_file)\n",
    "    \n",
    "    # Check NEAs in NON_NEA df\n",
    "    notnea_df = output_df[output_df['Neo2'] < digest2_thresh]\n",
    "    misidentified_nea = notnea_df[notnea_df['class'] == 0]\n",
    "    print(f\"Number of misidentified NEAs in {digest2_file}: {misidentified_nea.shape[0]}\")\n",
    "    #print(misidentified_nea)\n",
    "    \n",
    "    # Check for non-NEAs in NEA df\n",
    "    nea_df = output_df[output_df['Neo2'] >= digest2_thresh]\n",
    "    misidentified_nonnea = nea_df[nea_df['class'] == 1]\n",
    "    print(f\"Number of misidentified non-NEAs in {digest2_file}: {misidentified_nonnea.shape[0]}\")\n",
    "    #print(misidentified_nonnea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_optimal_thresholds(optimal_thresh_file: str, digest2_file: str) -> None:\n",
    "    \"\"\" Analyze the optimal thresholds from digest2. \"\"\"\n",
    "\n",
    "    # The file only contains the trksubs that are not NEAs\n",
    "    thresh_df = pd.read_csv(optimal_thresh_file, header=None, names=['trksub'])\n",
    "    print(f\"Number of trksubs in {optimal_thresh_file}: {thresh_df.shape[0]}\")\n",
    "    digest2_df = pd.read_csv(digest2_file)\n",
    "    \n",
    "    # Count the number of NEAs and non-NEAs\n",
    "    neas = digest2_df[digest2_df[\"class\"] == 0]\n",
    "    # We want to check if there are NEAs in the optimal thresholds file\n",
    "    nea_count = neas[neas['trksub'].isin(thresh_df['trksub'])].shape[0]\n",
    "    print(f\"Number of NEAs in {optimal_thresh_file}: {nea_count}\")\n",
    "    #print(neas[neas['trksub'].isin(thresh_df['trksub'])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Match trksubs with designations ------ \n",
      "Total number of NEAs in the off-ecliptic and on-ecliptic data: 1280\n",
      "Total number of non-NEAs in the off-ecliptic and on-ecliptic data: 550120\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Main execution flow \n",
    "1. Create a dictionary that matches the trksubs to the designations given by the NEO Surveyor Team\n",
    "2. Analyze each XML file\n",
    "3. Run digest2 on each XML file\n",
    "4. Create the output format needed by the filtering and the machine learning code\n",
    "\"\"\"\n",
    "\n",
    "# Match trksubs with designations\n",
    "print(\" ------ Match trksubs with designations ------ \")\n",
    "trksub_desig = match_desig_trksub(off_ecliptic_file, on_ecliptic_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ------ Create digest2 output format for each XML file ------ \")\n",
    "create_digest2_output(xml_dir, xml_files, trksub_desig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Analyze output files ------ \n",
      "Number of NEAs in 2024-10-21T16_54_54.398_000000R8.digest2_filter: 36\n",
      "Number of non-NEAs in 2024-10-21T16_54_54.398_000000R8.digest2_filter: 418\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Main execution flow \n",
    "5. Analyze the output files \n",
    "\"\"\"\n",
    "# Analyze the output files\n",
    "for xml_file in xml_files:\n",
    "    print(\" ------ Analyze output files ------ \")\n",
    "    #analyze_digest2_output(xml_file.replace(\".xml\", \".digest2\"),digest2_thresh=90)\n",
    "    analyze_digest2_output(xml_file.replace(\".xml\", \".digest2_filter\"), digest2_thresh=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the digest2 score for the missing NEAs\n",
    "We noticed that if we set digest2=100, we are then missing some NEAs (between 60% and 74% of objects are actually correctly identified) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ Analyze missing NEAs ------ \n",
      "Number of misidentified NEAs in 2024-10-21T16_54_54.398_000000R8.digest2_filter: 14\n",
      "Number of misidentified non-NEAs in 2024-10-21T16_54_54.398_000000R8.digest2_filter: 1\n"
     ]
    }
   ],
   "source": [
    "# Analyze the output files\n",
    "for xml_file in xml_files:\n",
    "    print(\" ------ Analyze missing NEAs ------ \")\n",
    "    analyze_missing_NEAs(xml_file.replace(\".xml\", \".digest2_filter\"), digest2_thresh=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code from github repository\n",
    "from neocp_filter import filter_and_output_passed_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 2024-10-21T16_54_54.398_000000R8.xml\n"
     ]
    }
   ],
   "source": [
    "for xml in xml_files:\n",
    "    print(f\"Processing file: {xml}\")\n",
    "    input_csv = xml.replace(\".xml\", \".digest2_filter\")\n",
    "    threshold_json = f\"/Users/fspoto/Work/MPC/Work_in_progress/NEOSurveyor/Fulldigest2/ML_digest2_methods/data/optimal_thresholds.json\"\n",
    "    output_csv = input_csv.replace(\".digest2_filter\", \"_filter_passed.csv\")\n",
    "\n",
    "    filter_and_output_passed_entries(input_csv, threshold_json, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing optimal thresholds for 2024-10-21T16_54_54.398_000000R8_filter_passed.csv and 2024-10-21T16_54_54.398_000000R8.digest2_filter\n",
      "Number of trksubs in 2024-10-21T16_54_54.398_000000R8_filter_passed.csv: 312\n",
      "Number of NEAs in 2024-10-21T16_54_54.398_000000R8_filter_passed.csv: 1\n"
     ]
    }
   ],
   "source": [
    "# Analyze optimal thresholds output\n",
    "for xml in xml_files:\n",
    "    optimal_thresh_file = xml.replace(\".xml\", \"_filter_passed.csv\")\n",
    "    digest2_file = xml.replace(\".xml\", \".digest2_filter\")\n",
    "    print(f\"Analyzing optimal thresholds for {optimal_thresh_file} and {digest2_file}\")\n",
    "    analyze_optimal_thresholds(optimal_thresh_file, digest2_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the machine learning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 2024-10-21T16_54_54.398_000000R8.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 10:31:10.512726: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "\n",
      "=== Evaluating GBM ===\n",
      "Shape of input to GBM predict_proba: (454, 26)\n",
      "Accuracy: 0.9692\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85        49\n",
      "           1       0.98      0.99      0.98       405\n",
      "\n",
      "    accuracy                           0.97       454\n",
      "   macro avg       0.93      0.91      0.92       454\n",
      "weighted avg       0.97      0.97      0.97       454\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 41   8]\n",
      " [  6 399]]\n",
      "Results saved to ML_digest2_methods/models/GBM_predictions.csv\n",
      "\n",
      "=== Evaluating RF ===\n",
      "Accuracy: 0.9670\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84        49\n",
      "           1       0.98      0.99      0.98       405\n",
      "\n",
      "    accuracy                           0.97       454\n",
      "   macro avg       0.92      0.90      0.91       454\n",
      "weighted avg       0.97      0.97      0.97       454\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 40   9]\n",
      " [  6 399]]\n",
      "Results saved to ML_digest2_methods/models/RF_predictions.csv\n",
      "\n",
      "=== Evaluating SGD ===\n",
      "Error evaluating SGD: Can't get attribute 'Log' on <module 'sklearn.linear_model._sgd_fast' from '/Users/fspoto/anaconda3/envs/NEOSurveyor/lib/python3.11/site-packages/sklearn/linear_model/_sgd_fast.cpython-311-darwin.so'>\n",
      "\n",
      "=== Evaluating NN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fspoto/anaconda3/envs/NEOSurveyor/lib/python3.11/pickle.py:1718: UserWarning: [10:31:15] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:82: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "/Users/fspoto/anaconda3/envs/NEOSurveyor/lib/python3.11/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/fspoto/anaconda3/envs/NEOSurveyor/lib/python3.11/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/fspoto/anaconda3/envs/NEOSurveyor/lib/python3.11/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy: 0.9383\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.75        49\n",
      "           1       0.98      0.95      0.96       405\n",
      "\n",
      "    accuracy                           0.94       454\n",
      "   macro avg       0.82      0.91      0.86       454\n",
      "weighted avg       0.95      0.94      0.94       454\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 43   6]\n",
      " [ 22 383]]\n",
      "Results saved to ML_digest2_methods/models/NN_predictions.csv\n",
      "\n",
      "=== Model Comparison ===\n",
      "Model  Accuracy\n",
      "  GBM  0.969163\n",
      "   RF  0.966960\n",
      "   NN  0.938326\n",
      "\n",
      "Detailed results saved to ML_digest2_methods/models/model_evaluation_results.txt\n"
     ]
    }
   ],
   "source": [
    "ml_python = \"ML_digest2_methods/src/testing_pipeline.py\"\n",
    "model_dir = \"ML_digest2_methods/models/\"\n",
    "for xml in xml_files:\n",
    "    print(f\"Processing file: {xml}\")\n",
    "    input_csv = xml.replace(\".xml\", \".digest2_ml\")\n",
    "    # Run the machine learning code\n",
    "    subprocess.run(\n",
    "        f\"python3 {ml_python} --model_dir {model_dir} --test_data {input_csv} --save_results\",\n",
    "        shell=True, check=True\n",
    "    )\n",
    "    # Copy the results to the current directory\n",
    "    shutil.copyfile(f\"ML_digest2_methods/models/GBM_predictions.csv\", f\"{xml.replace('.xml', '_GBM_predictions.csv')}\")\n",
    "    shutil.copyfile(f\"ML_digest2_methods/models/confusion_matrices.png\", f\"{xml.replace('.xml', '_confusion_matrices.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEOSurveyor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
